# -*- coding: utf-8 -*-
"""Amazon Product Review Sentiment Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MsQLThSpAj7XQYVJ8465M-_P3_U-M1Ad
"""

from lxml import html  
import requests
import pandas as pd

amazon_url = 'https://www.amazon.in/Redmi-Sky-Blue-64GB-Storage/product-reviews/B08697N43N/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'
user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'
headers = {'User-Agent': user_agent}
page = requests.get(amazon_url, headers = headers)
parser = html.fromstring(page.content)

xpath_reviews = '//div[@data-hook="review"]'
reviews = parser.xpath(xpath_reviews)


xpath_rating  = './/i[@data-hook="review-star-rating"]//text()' 
xpath_title   = './/a[@data-hook="review-title"]//text()'
#xpath_author  = './/a[@data-hook="review-author"]//text()'
xpath_date    = './/span[@data-hook="review-date"]//text()'
xpath_body    = './/span[@data-hook="review-body"]//text()'
xpath_helpful = './/span[@data-hook="helpful-vote-statement"]//text()'

reviews_df= pd.DataFrame()
for review in reviews:
    rating  = review.xpath(xpath_rating)
    title   = review.xpath(xpath_title)
    #author  = review.xpath(xpath_author)
    date    = review.xpath(xpath_date)
    body    = review.xpath(xpath_body)
    helpful = review.xpath(xpath_helpful)
    
    review_dict = {'rating': rating,
                   'title': title,            
                   'date': date,
                   'body': body,
                   'helpful': helpful}
    reviews_df = reviews_df.append(review_dict, ignore_index=True)

pip install lxml

pip install requests lxml dateutil ipython pandas



reviews_df

for i in range(9):
  reviews_df.iloc[i]['body'].pop(0)

for i in range(9):
  reviews_df.iloc[i]['title'].pop(0)

for i in range(9):
  reviews_df.iloc[i]['title'].pop(-1)

for i in range(9):
  reviews_df.iloc[i]['body'].pop(-1)

reviews_df

reviews_df["body"]= reviews_df["body"].astype(str)

reviews_df["rating"]= reviews_df["rating"].astype(str)



#b=a[2:]

#reviews_df["rating"]= reviews_df["rating"].astype(str) 
list_avg = []
for i in range(9):
  b = reviews_df.iloc[i]['rating'].split()[0]
  a = b[2:]
  Float_a = float(a)
  
  list_avg.append(Float_a)
print(list_avg)

sum_avg = 0
for i in range(len(list_avg)):
  sum_avg = sum_avg + list_avg[i]
average_rating = sum_avg / 9
print(round(average_rating,2))

import nltk
nltk.download('vader_lexicon')

neg_sent=0 #counter of negative sentiments
pos_sent=0
neu_sent=0

from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords


from nltk.sentiment.vader import SentimentIntensityAnalyzer

from nltk.sentiment.vader import SentimentIntensityAnalyzer

sid = SentimentIntensityAnalyzer()

def sentiment_analyse(sentiment_text):
    score = sid.polarity_scores(sentiment_text)
    print(score)
    neg=score['neg']
    pos=score['pos']
    if neg>pos :
        print( "negative sentiment")
        global neg_sent 
        neg_sent = neg_sent + 1
    elif pos>neg :
        print("positive sentiment")
        global pos_sent
        pos_sent = pos_sent + 1
    else :
        print("neutral sentiment")
        global neu_sent
        neu_sent = neu_sent + 1
#sentiment_analyse("She is best")

for i in range(9):
 sentiment_analyse(reviews_df.iloc[i]['body'])

if (neg_sent>pos_sent):
  sentiment = "Negative"
elif (neg_sent<pos_sent):
  sentiment = "Positive"
else:
  sentiment = "Neural"

print("RATING OF THE PRODUCT Redmi 9 IS:\t" , average_rating )
print("SENTIMENT OF THE PRODUCT Redmi 9 IS:\t" , sentiment )

